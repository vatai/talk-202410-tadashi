#+startup: beamer
#+include: preamble.org
#+options: h:2 ':t toc:nil
#+reveal_hlevel: 2
#+latex_compiler: xelatex
#+latex_class_options: [presentation, aspectratio=169]
# #+latex_header: \usepackage[OT1]{fontenc}
#+latex_header: \usepackage{concmath, subcaption, qrcode}
#+latex_header_extra: \usefonttheme{serif}
#+latex_header: \usepackage{tikz}
#+latex_header: \usepackage{marvosym}
#+latex_header: \usepackage[marvosym]{tikzsymbols}
#+latex_header: \usetikzlibrary{arrows, matrix, arrows.meta, shapes, shapes.arrows, shapes.multipart, shapes.symbols, fadings, fit, positioning, decorations.pathreplacing, angles, quotes}
#+latex_header: \setbeamercovered{transparent}
#+title: Enabling AI-based Automated Code Generation with Guaranteed Correctness
#+date: http://vatai.github.io/
#+author: *E. Vatai*, A. Drozd, I. R. Ivanov, Y. Ren, M. Wahib
#+bibliography: ~/overleaf/tadashi-paper/main.bib

* Tadashi
** ML approaches to correctness in code generation
*** Left column
:PROPERTIES:
:beamer_col: 0.45
:END:
- <1-> Extensive unit testing
  - Coverage
  - Writing tests is not trivial
- <3-> Surrogate ML model
  - Trust issues
- <4-> Limit ML to short sequences of instructions
- <4-> Limit ML to a set of determined transformations
  - Not general
- <5-> Symbolic execution
  - Not well established
- <6-> Round-trip
  - Trust issues
*** Right column
:PROPERTIES:
:beamer_col: 0.45
:END:
**** Edsger W. Dijkstra
:PROPERTIES:
:beamer_act: <2->
:END:
#+begin_quote
"Program testing can be used to show the presence of bugs, but never to show their absence!"

#+end_quote
** XKCD
:PROPERTIES:
:beamer_env: fullframe
:END:
#+attr_latex: :width 0.5\textwidth
[[file:./figs/xkcd.png]]
** All you need is to sample the set of correct transformations
- <+-> *ML codegen is transformations* on a reference implementation
- <+-> ML can *explore the space of transformations* to find a faster version
- <+-> But we also need *correctness*
  # - Transformation is allowed \rightarrow perform the transformation
** TADASHI: *loop transformations* with correctness check
:PROPERTIES:
:name: overview
:END:
[[./figs/sampling.pdf]]
** Reinforcement learning
- Actions = primitive transformations; Reward = walltime; Environment = correctness
#+attr_latex: :width 0.7\textwidth
[[./figs/ml-rl.pdf]]
** Supervised learning
- Dataset generation (legal transformations); Sample label: runtime
#+attr_latex: :width 0.7\textwidth
[[./figs/ml-sl.pdf]]
** Evolutionary algorithms
- Exploration and explorations; Candidates = transformations; Objective function = runtime
#+attr_latex: :width 0.7\textwidth
[[./figs/ml-ea.pdf]]
** LLM agents
- Dataset generation; High quality correct transformations; Caveat! Hallucinations are possible!
#+attr_latex: :width 0.8\textwidth
[[./figs/ml-ul.pdf]]
** Auto-Tuning
- Brute forcing on a bounded region of the space (grid search)
#+attr_latex: :width 0.7\textwidth
[[./figs/ml-at.pdf]]
** Grand vision
*** Large scale optimisation framework
#+begin_center
#+begin_export latex
\begin{tikzpicture}[
  decoration={random steps,segment length=1mm,amplitude=0.2pt},
  every node/.style={decorate, draw}, align=center, font=\small,
  every edge/.style={draw, ->, decorate},
]
\node (new) {New\\supercomputer};
\node [right of=new, node distance=3cm] (train) {Train\\Tadashi};
\node [below of=new] (newcode) {New code};
\node [below of=train] (infer) {Inference};
\node [right of=infer, node distance=2cm] (done) {\Huge \Smiley};
\path
(new) edge (train)
(newcode) edge (infer)
(train) edge (infer)
(infer) edge (done);
\end{tikzpicture}
#+end_export
#+end_center
*** Wise words
#+begin_quote
Spending 6h on the whole machine to make the code 5% faster will pay off.  -- N. D.
#+end_quote
** Now: Support C, Harness, and Transformations

#+attr_latex: :booktabs
    | ~TrEnum~              | Args                             |
    |---------------------+----------------------------------|
    | ~TILE~                | tile size                        |
    | ~INTERCHANGE~         | --                               |
    | ~FULL_FUSE~           | --                               |
    | ~FUSE~                | 2 loop indices                   |
    | ~FULL_SHIFT_VAL~      | const shift value                |
    | ~PARTIAL_SHIFT_VAL~   | stmt idx, const shift value      |
    | ~FULL_SHIFT_VAR~      | coeff, shift iter idx            |
    | ~PARTIAL_SHIFT_VAR~   | stmt idx, coeff, shift iter idx  |
    | ~FULL_SHIFT_PARAM~    | coeff, shift param idx           |
    | ~PARTIAL_SHIFT_PARAM~ | stmt idx, coeff, shift param idx |
    | ~SCALE~               | coeff                            |
    | ~SET_PARALLEL~        | --                               |
    | ~SET_LOOP_OPT~        | ~AstLoopType~ enum                 |
** Future:
*** Left column
:PROPERTIES:
:beamer_col: 0.48
:END:
- New language
  - Fortran (MLIR, Polygeist)
  - CUDA (PPCG?)
- Better use of the polyhedral model
  - New transformations: Loop fission, unrolling, etc.
  - Expansion and extension nodes
  - More efficient legality check
*** Right column
:PROPERTIES:
:beamer_col: 0.48
:END:
- Harness/infrastructure
  - Scheduler support (slurm, pjsub)
  - Compiler flags
- ML (target list)
  - Reinforcement Learning
  - LLM Agents
  - Auto-Tuning
  - Supervised Learning
  - Evolutionary Algorithms
** Random RL
#+begin_src python
def train_model(app, num_iter=3, net=Model()):
  loop_nests = LoopNests(app)
  ln = loop_nests[0]
  for i in range(num_iter):
    loop_idx, tr, args = net.transform(ln)
    loop = ln.schedule_tree[loop_idx]
    legal = loop.transform(tr, *args)
    if not legal:
      node.rollback()
      continue
    loop_nests.generate_code("output.c")
    app.compile()
    t = app.measure()
    # net.update(loop_idx, tr, args, legal, t)
#+end_src
** Breakdown (primitive)
#+attr_latex: :width 0.7\textwidth
[[./figs/plot-breakdown-abs-1.pdf]]
** Breakdown (10 seq)
#+attr_latex: :width 0.7\textwidth
[[./figs/plot-breakdown-abs-10.pdf]]
** Throughput
#+attr_latex: :width 0.7\textwidth
[[./figs/plot-throughput.pdf]]
** Representations
Different levels of abstraction
- source code [Stein: Paraphrasing etc.]
- abstract syntax tree (AST) [Shido: Tree-LSTM etc.]
- polyhedral [Baghdadi: Tiramisu]
- dependency graphs [Cummins: ProGraML]
- intermediate Representations (IR) [Ben-nun: inst2vec]
- assembly instructions [Deepmind: Faster sorting]
** Polyhedral model
*** Left column
:PROPERTIES:
:beamer_col: 0.45
:END:
**** Components
1. $\mathcal{D}_S = \{ S[\vec{i}] \in \mathbb{Z}^n : \mathbf{A} \vec{i} + \mathbf{b} \le \mathbf{0}  \}$
2. $\theta(S[i, j]) = t = (i, j)$
3. $G=(V, E)$:
   - $V=\{ S_0, S_1, \ldots\}$,
   - $E=\{ S_i[\vec{d}] \mapsto S_j[\vec{r}], \ldots \}$

*** Right column
:PROPERTIES:
:beamer_col: 0.45
:END:
**** Mini example
#+begin_src C
for(int i = 0; i < N; i++)
  for(int j = 1; j < M; j++)
    A[i, j] += A[i, j-1]; // S[i,j]
#+end_src
** Legality
:PROPERTIES:
:beamer_env: fullframe
:END:
*** Iterspace column
:PROPERTIES:
:beamer_col: 0.45
:END:
\begin{figure}
  \centering
  \subcaptionbox{$\theta(S[i, j]) = (i, j)$  \label{sf:schedule-i-j}}
  {\includegraphics[width=0.48\linewidth]{figs/schedule-i-j}}
  \subcaptionbox{$\theta(S[i, j]) = (j, i)$  \label{sf:schedule-j-i}}
  {\includegraphics[width=0.48\linewidth]{figs/schedule-j-i}}
  \subcaptionbox{$\theta(S[i, j]) = (i+j, j)$\label{sf:schedule-ipj-j}}
  {\includegraphics[width=0.48\linewidth]{figs/schedule-ipj-j}}
  \subcaptionbox{$\theta(S[i, j]) = (i, -j)$ \label{sf:schedule-i-mj}}
  {\includegraphics[width=0.48\linewidth]{figs/schedule-i-mj}}
  \label{fig:schedules}
\end{figure}
**** COMMENT Examples
[[./figs/4schedules.png]]
*** Graph column
:PROPERTIES:
:beamer_col: 0.52
:END:
**** Legality check
#+attr_latex: :width \linewidth
[[./figs/legality.pdf]]
** End-to-end example
#+begin_src python
  import tadashi
  app = tadahis.Simple("input.c")
  scops = tadahi.Scops(app)
  node = scops[0].schedule_tree[1]
  tr, args = tadashi.TrEnum.TILE, 16
  legal = node.transform(tr, args)
  if legal:
      scops.generate_code(output_path="output.c")
      app.compile()
      t = app.measure()
      printf(f"Walltime: {t}")
#+end_src
** Under the hood
:PROPERTIES:
:beamer_env: fullframe
:END:
#+attr_latex: :width 0.65\textwidth
[[./figs/design.pdf]]
** That's all folks!
- i. https://vatai.github.io/
- ii. https://github.com/vatai/tadashi/
- iii. https://arxiv.org/abs/2410.03210

\bigskip

i. \qrcode{https://vatai.github.io/} \hfill
ii. \qrcode{https://github.com/vatai/tadashi/} \hfill
iii. \qrcode{https://arxiv.org/abs/2410.03210}
** COMMENT Where do we go from here?
*** Machine learning column
:PROPERTIES:
:beamer_col: 0.48
:END:
**** Machine learning!
- Reinforcement Learning
- Supervised Learning
- Evolutionary Algorithms
- LLM Agents
- Auto-Tuning
*** Transfer learning column
:PROPERTIES:
:beamer_col: 0.48
:END:
**** Three levels of transfer learning
1. *No Transfer*: Train from scratch for each (SW, HW) pair
2. Transfer to *new software*
3. Transfer to *new hardware*

Expected:
   - Less retraining
   - Better exploration \Rightarrow better results for a given kernel
** COMMENT Overview again
:PROPERTIES:
:beamer_ref: overview
:beamer_env: againframe
:END:
** COMMENT Status quo
*** Not an average AI talk

[[./figs/disclaimer.jpg]]

#+attr_latex: :options basicstyle=\Huge\ttfamily
#+begin_center
*NOT* "enabled by AI"

"Enabling AI" = No AI here (yet!)

#+end_center

*** Why is this important?
:PROPERTIES:
:beamer_env: ignoreheading
:END:
**** Left column
:PROPERTIES:
:beamer_col: 0.45
:beamer_opt: t
:END:

***** AI hallucinations
- We can all [[./figs/hands.png][agree]] AI's [[file:./figs/granny.png][hallucinate]]!

- Suggested solution?
  - "Treat them like any other (not entirely trustworthy) human!"

**** Right column
:PROPERTIES:
:beamer_col: 0.45
:beamer_opt: t
:END:

***** XKCD said it best
#+attr_latex: :width 5cm
[[./figs/xkcd_com_1838.png]]

*** What about code?

- When AI hallucinate wrong code:
  - Syntactically incorrect:
    - *Compiler* can check!
  - Semantic correctness???
    - *TESTS*!

- It should be *different for code*!

- Code is not natural language -- it should be more manageable!
  - And it is!

*** Why is this important?

- Performance portability is extremely important
- More than necessary (PhD-level) work-hours wasted!
  [[./figs/ecp-logo.png]]
  [[./figs/fugaku.jpeg]]

*** How is it relevant?
**** Left
:PROPERTIES:
:beamer_col: 0.55
:beamer_opt: t
:END:
***** Tadashi does it /right/!
- Tadashi(i), Japanese word for "correct"
- Polyhedral transformation
- On loop nests (SCoP restriction)
- Correctness check
- Code generation
**** Right
:PROPERTIES:
:beamer_col: 0.40
:beamer_opt: t
:END:

***** The target codes are a good match
- HPC/Science codes:
  - Regular!
  - Time critical!
  - Mission critical!

*** Imagine

*** Scalability

*** Current approaches

- In case of code = testing
  - Deepmind, restrict the problem -- doesn't scale
  # [[./figs/obama.png]]
- Codes begging to be rewritten

* COMMENT Notes
** Something in the way
** Necessary step
** Precursor
** Adopt existing code
** Critical layer
** Explore
** Independent of the ML
** Agent
** Call for colaboration/action
